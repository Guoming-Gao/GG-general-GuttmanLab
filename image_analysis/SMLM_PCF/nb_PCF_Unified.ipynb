{"cells": [{"cell_type": "code", "metadata": {}, "outputs": [], "source": ["import os\n", "from shapely.geometry import Point, Polygon\n", "from shapely.vectorized import contains\n", "from tifffile import imread\n", "import random\n", "import numpy as np\n", "import pandas as pd\n", "from tqdm.auto import tqdm\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "from concurrent.futures import ProcessPoolExecutor, as_completed\n", "from functools import partial\n", "import multiprocessing as mp\n", "from scipy.ndimage import gaussian_filter\n", "from skimage.measure import find_contours\n", "\n", "sns.set(color_codes=True, style=\"white\")\n"]}, {"cell_type": "markdown", "metadata": {}, "outputs": [], "source": ["# Parameters\n"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "source": ["# =============================================================================\n", "# ANALYSIS MODE\n", "# =============================================================================\n", "# ROI_MODE can be:\n", "# 'image_automated' - Uses image thresholding/contours to find ROIs (Cellpose/Blobs style)\n", "# 'manual_roi'      - Loads ROI coordinate files from disk\n", "ROI_MODE = 'image_automated'\n", "\n", "# =============================================================================\n", "# SPATIAL ANALYSIS PARAMETERS\n", "# =============================================================================\n", "nm_per_pxl = 23.4  # Nanometers per pixel\n", "r_max_nm = 1120    # Maximum distance to analyze (nm)\n", "ringwidth_nm = 100 # Width of each distance bin (nm)\n", "dr_slidingrings_nm = 20 # Step size between adjacent overlapping rings (nm)\n", "\n", "# =============================================================================\n", "# FILE PATHS\n", "# =============================================================================\n", "# folder = \"/Volumes/guttman/Guoming_Gao-Resnick/Data_BIF/DEFAULT_USER/20250424_ONIdemo_Guoming/Guoming_data/dSTORM/dSTORM_tif/Malat1\"\n", "# os.chdir(folder)\n", "\n", "# SMLM Data files\n", "ch1_file = \"dSTORM1_TX_nodiff_Malat_AF647_AF488-1-cropped-left-driftcorrected10k.csv\"\n", "ch2_file = \"dSTORM1_TX_nodiff_Malat_AF647_AF488-1-cropped-right-driftcorrected10k.csv\"\n", "\n", "# Configuration for 'image_automated' mode\n", "fname_segmentation_reference = \"dSTORM1_TX_nodiff_Malat_AF647_AF488-1_befbleach-composite-5x.tif\"\n", "sigma_smooth = 30\n", "threshold_normalized = 0.2\n", "area_threshold_pxl = 1e4\n", "\n", "# Configuration for 'manual_roi' mode\n", "roi_file_pattern = \"cell\" \n"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "source": ["# === DISTANCE BIN SETUP ===\n", "bin_starts = np.arange(0, r_max_nm - ringwidth_nm, dr_slidingrings_nm)\n", "bin_ends = bin_starts + ringwidth_nm\n", "bins = bin_starts # For plotting\n", "\n", "# === PRECOMPUTE RING AREAS ===\n", "ring_areas_nm2 = np.pi * (bin_ends**2 - bin_starts**2)\n", "ring_areas_pxl2 = ring_areas_nm2 / (nm_per_pxl**2)\n"]}, {"cell_type": "markdown", "metadata": {}, "outputs": [], "source": ["# Functions\n"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "source": ["def create_cell_polygon(roi_file, nm_per_pxl):\n", "    \"\"\"Create a Shapely Polygon from manual ROI coordinate file.\"\"\"\n", "    try:\n", "        coords = pd.read_csv(roi_file, sep=\"\\t\", header=None)\n", "        coords_pxl = [tuple(row * 1000 / nm_per_pxl) for _, row in coords.iterrows()]\n", "        return Polygon(coords_pxl)\n", "    except Exception as e:\n", "        print(f\"Error loading {roi_file}: {e}\")\n", "        return None\n", "\n", "def corr_within_cell_polygon_truly_vectorized(df, cell_polygon):\n", "    \"\"\"Fast vectorized point-in-polygon filtering.\"\"\"\n", "    minx, miny, maxx, maxy = cell_polygon.bounds\n", "    mask_bounds = (df[\"x\"] >= minx) & (df[\"x\"] <= maxx) & (df[\"y\"] >= miny) & (df[\"y\"] <= maxy)\n", "    df_candidates = df[mask_bounds]\n", "    if len(df_candidates) == 0:\n", "        return np.array([]), np.array([])\n", "    mask_within = contains(cell_polygon, df_candidates[\"x\"], df_candidates[\"y\"])\n", "    final_points = df_candidates[mask_within]\n", "    return final_points[\"x\"].values, final_points[\"y\"].values\n", "\n", "def process_reference_point_vectorized(i, x_ref, y_ref, x_interest, y_interest, cell_polygon, bin_starts, bin_ends, nm_per_pxl, ring_areas_pxl2):\n", "    \"\"\"Core PCF logic for a single reference point (vectorized).\"\"\"\n", "    # Edge correction\n", "    rings = [Point(x_ref[i], y_ref[i]).buffer(end).difference(Point(x_ref[i], y_ref[i]).buffer(start))\n", "             for start, end in zip(bin_starts / nm_per_pxl, bin_ends / nm_per_pxl)]\n", "\n", "    intersect_areas = np.array([cell_polygon.intersection(Polygon(ring), grid_size=0.1).area for ring in rings])\n", "    edge_correction_factors = 1 / (intersect_areas / ring_areas_pxl2)\n", "\n", "    # Distances\n", "    distances = np.sqrt((x_ref[i] - x_interest) ** 2 + (y_ref[i] - y_interest) ** 2) * nm_per_pxl\n", "\n", "    # Histogram\n", "    hist_matrix = (bin_starts[:, np.newaxis] <= distances) & (bin_ends[:, np.newaxis] >= distances)\n", "    hist_per_point = np.sum(hist_matrix, axis=1)\n", "\n", "    return hist_per_point * edge_correction_factors\n", "\n", "def worker_pcf(cell_data, bin_starts, bin_ends, nm_per_pxl, ring_areas_pxl2, ring_areas_nm2):\n", "    \"\"\"Worker function for multiprocessing.\"\"\"\n", "    x_ref, y_ref, x_interest, y_interest, cell_polygon, rho_interest_per_nm2, cell_id = cell_data\n", "\n", "    if len(x_ref) == 0 or len(x_interest) == 0:\n", "        return cell_id, None\n", "\n", "    hist_results = []\n", "    # Loop over reference points within this cell\n", "    for i in range(len(x_ref)):\n", "        res = process_reference_point_vectorized(i, x_ref, y_ref, x_interest, y_interest, cell_polygon, bin_starts, bin_ends, nm_per_pxl, ring_areas_pxl2)\n", "        hist_results.append(res)\n", "\n", "    norm_factors = len(x_ref) * ring_areas_nm2 * rho_interest_per_nm2\n", "    pcf_result = np.sum(hist_results, axis=0) / norm_factors\n", "    return cell_id, pcf_result\n"]}, {"cell_type": "markdown", "metadata": {}, "outputs": [], "source": ["# Processing\n"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "source": ["print(\"Loading localization data...\")\n", "# Load once for all ROIs\n", "df_interest_raw = pd.read_csv(ch1_file, skiprows=lambda i: i > 0 and random.random() > 0.1)\n", "df_interest_raw[\"x\"] = df_interest_raw[\"x [nm]\"] / nm_per_pxl\n", "df_interest_raw[\"y\"] = df_interest_raw[\"y [nm]\"] / nm_per_pxl\n", "\n", "df_ref_raw = pd.read_csv(ch2_file)\n", "df_ref_raw[\"x\"] = df_ref_raw[\"x [nm]\"] / nm_per_pxl\n", "df_ref_raw[\"y\"] = df_ref_raw[\"y [nm]\"] / nm_per_pxl\n", "print(f\"Loaded {len(df_interest_raw)} interest points and {len(df_ref_raw)} reference points.\")\n"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "source": ["polygons = []\n", "cell_ids = []\n", "\n", "if ROI_MODE == 'image_automated':\n", "    print(f\"Segmenting {fname_segmentation_reference}...\")\n", "    img = imread(fname_segmentation_reference)\n", "    img_ave = np.mean(img, axis=0) if img.ndim == 3 else img\n", "    img_smoothed = gaussian_filter(img_ave, sigma=sigma_smooth)\n", "    img_norm = (img_smoothed - img_smoothed.min()) / (img_smoothed.max() - img_smoothed.min())\n", "    img_thresh = img_norm > threshold_normalized\n", "\n", "    contours = find_contours(img_thresh, 0.5)\n", "    for idx, contour in enumerate(contours):\n", "        if len(contour) >= 3:\n", "            poly = Polygon(contour[:, [1, 0]]) # y,x -> x,y\n", "            if poly.is_valid and poly.area > area_threshold_pxl:\n", "                polygons.append(poly)\n", "                cell_ids.append(f\"auto_{idx}\")\n", "    print(f\"Found {len(polygons)} polygons after filtering.\")\n", "\n", "elif ROI_MODE == 'manual_roi':\n", "    print(f\"Loading manual ROIs matching {roi_file_pattern}...\")\n", "    roi_files = sorted([f for f in os.listdir(\".\") if roi_file_pattern in f and f.endswith(\".txt\")])\n", "    for f in roi_files:\n", "        poly = create_cell_polygon(f, nm_per_pxl)\n", "        if poly:\n", "            polygons.append(poly)\n", "            cell_ids.append(os.path.basename(f))\n", "    print(f\"Loaded {len(polygons)} polygons.\")\n"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "source": ["# Prepare task list\n", "tasks = []\n", "for poly, cid in zip(polygons, cell_ids):\n", "    x_r, y_r = corr_within_cell_polygon_truly_vectorized(df_ref_raw, poly)\n", "    x_i, y_i = corr_within_cell_polygon_truly_vectorized(df_interest_raw, poly)\n", "\n", "    if len(x_r) > 0 and len(x_i) > 0:\n", "        area_nm2 = poly.area * (nm_per_pxl**2)\n", "        rho_i = len(x_i) / area_nm2\n", "        tasks.append((x_r, y_r, x_i, y_i, poly, rho_i, cid))\n", "\n", "print(f\"Processing {len(tasks)} valid ROIs in parallel...\")\n", "\n", "results = {}\n", "n_proc = min(len(tasks), mp.cpu_count() - 1) if len(tasks) > 0 else 1\n", "\n", "if tasks:\n", "    with ProcessPoolExecutor(max_workers=n_proc) as executor:\n", "        futures = {executor.submit(worker_pcf, t, bin_starts, bin_ends, nm_per_pxl, ring_areas_pxl2, ring_areas_nm2): t for t in tasks}\n", "        for future in tqdm(as_completed(futures), total=len(futures)):\n", "            cid, pcf = future.result()\n", "            if pcf is not None:\n", "                results[cid] = pcf\n", "\n", "print(f\"Completed processing. Results for {len(results)} ROIs.\")\n"]}, {"cell_type": "markdown", "metadata": {}, "outputs": [], "source": ["# Visualization\n"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "source": ["if results:\n", "    plt.figure(figsize=(8, 6))\n", "    all_pcfs = []\n", "    for cid, pcf in results.items():\n", "        plt.plot(bins, pcf, color='gray', alpha=0.3)\n", "        all_pcfs.append(pcf)\n", "\n", "    mean_pcf = np.mean(all_pcfs, axis=0)\n", "    plt.plot(bins, mean_pcf, color='red', lw=2, label='Mean PCF')\n", "    plt.axhline(1, ls='--', color='black', alpha=0.5)\n", "    plt.xlabel('Distance (nm)')\n", "    plt.ylabel('G(r)')\n", "    plt.title(f'PCF Analysis (n={len(results)})')\n", "    plt.legend()\n", "    plt.show()\n"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.21"}}, "nbformat": 4, "nbformat_minor": 2}