{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b321931-f36b-434e-838d-61017e678133",
   "metadata": {},
   "source": [
    "# PROG022 - Build Your Own Analysis: CODI CSV Analysis Tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa0b14f-78cb-4cb3-a4cb-72c520c38678",
   "metadata": {},
   "source": [
    "#### Box 1: Imports and Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4772a78-7ce2-4d10-b8d6-5519f80e63ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install ipywidgets==8.1.5\n",
    "import csv\n",
    "import json\n",
    "from natsort import natsorted\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from rich.progress import track"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a75287-8daa-48e0-89ce-5edaa43b21fb",
   "metadata": {},
   "source": [
    "#### Box 2: Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53868623-ab87-400f-932c-c6a510c39513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder must have Loc CSVs from CODI\n",
    "# Set parameters then run to generate checkboxes, then check the boxes and run Box 3\n",
    "\n",
    "folder = \"/Volumes/guttman/Guoming_Gao-Resnick/Data_BIF/DEFAULT_USER/20250424_ONIdemo_Guoming/Praneeth_data\"  # String: Path to folder containing data\n",
    "drift_correction = (\n",
    "    True  # Boolean: True or False (To drift correct CSVs using CODI drift correction)\n",
    ")\n",
    "filter_locs = False  # Boolean: True or False (To filter CSVs using CODI filters)\n",
    "save_ints = True  # Boolean: True or False (To save intermediate CSVs)\n",
    "keyword = \"dSTORM7\"  # String: Filter files in the folder for only those containing this string\n",
    "\n",
    "# Find point files, filter .json, and drift correction files\n",
    "points_list = natsorted(\n",
    "    [\n",
    "        i\n",
    "        for i in os.listdir(folder)\n",
    "        if (\n",
    "            i.endswith(\".csv\")\n",
    "            and (\"drift\" not in i)\n",
    "            and (\"output\" not in i)\n",
    "            and (\"result\" not in i)\n",
    "            and (\"SNR\" not in i)\n",
    "            and (\"densities\" not in i)\n",
    "            and (keyword in i)\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "if filter_locs:\n",
    "    filters_file = [g for g in os.listdir(folder) if ((g.endswith(\".json\")))][0]\n",
    "if drift_correction:\n",
    "    drift_files = [\n",
    "        h for h in os.listdir(folder) if (h.endswith(\"drift_correction.csv\"))\n",
    "    ]\n",
    "\n",
    "model_csv = pd.read_csv(os.path.join(folder, points_list[0]))\n",
    "channelTitle = [\n",
    "    p\n",
    "    for p in model_csv.columns\n",
    "    if (\"channel\" in p or \"Channel\" in p) and (\"Name\" not in p)\n",
    "][0]\n",
    "channels = np.unique(model_csv[channelTitle])\n",
    "\n",
    "# Set up checkboxes with column titles\n",
    "items = [widgets.Checkbox(value=False, description=c) for c in model_csv.columns]\n",
    "ui = widgets.GridBox(\n",
    "    items, layout=widgets.Layout(grid_template_columns=\"repeat(1,100px)\")\n",
    ")\n",
    "display(ui)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6e7735-4cd7-40a6-8f9a-4c6bbf4e88a4",
   "metadata": {},
   "source": [
    "#### Box 3: Run Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba649cc-4278-4e3f-9b9a-2f8ca61b9403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering\n",
    "def filter(points, filters_file, channels, channelTitle):\n",
    "    f = open(os.path.join(folder, filters_file))\n",
    "    filters = json.load(f)\n",
    "    idx = 0\n",
    "    for c in channels:\n",
    "        channel_array = points.loc[points[channelTitle] == c]\n",
    "        for i in filters[\"filters\"][str(c)[0]]:\n",
    "            column = [j for j in points.keys() if i in j]\n",
    "            if len(column) > 0:\n",
    "                channel_array = channel_array.loc[\n",
    "                    channel_array[column[0]]\n",
    "                    >= (filters[\"filters\"][str(c)[0]][i][\"min\"])\n",
    "                ]\n",
    "                channel_array = channel_array.loc[\n",
    "                    channel_array[column[0]]\n",
    "                    <= (filters[\"filters\"][str(c)[0]][i][\"max\"])\n",
    "                ]\n",
    "        if idx == 0:\n",
    "            points_filtered = channel_array\n",
    "            idx += 1\n",
    "        else:\n",
    "            points_filtered = pd.concat((points_filtered, channel_array))\n",
    "    points_filtered.columns = points.columns\n",
    "    if save_ints == True:\n",
    "        points_filtered.to_csv(\n",
    "            os.path.join(path, \"{}_filtered.csv\".format(os.path.split(path)[-1]))\n",
    "        )\n",
    "\n",
    "    return points_filtered\n",
    "\n",
    "\n",
    "# Analysis\n",
    "def analyze(\n",
    "    points,\n",
    "    items,\n",
    "    channels,\n",
    "    filter_locs,\n",
    "    points_original,\n",
    "    channelTitle,\n",
    "    frameTitle,\n",
    "    row_titles,\n",
    "):\n",
    "    # Set up data storage: rows are numChannels * numItems\n",
    "    # Columns are each CSV\n",
    "    data_dump = np.zeros(len(row_titles))\n",
    "\n",
    "    # Populate values for each channel\n",
    "    row = 0\n",
    "    for c in range(len(channels)):\n",
    "        # Populate number of locs before/after filtering if applicable\n",
    "        if filter_locs:\n",
    "            data_dump[row] = len(\n",
    "                points_original.loc[points_original[channelTitle] == channels[c]]\n",
    "            )\n",
    "            row += 1\n",
    "        data_dump[row] = len(points.loc[points[channelTitle] == channels[c]])\n",
    "        row += 1\n",
    "        channel_array = points.loc[points[channelTitle] == channels[c]]\n",
    "\n",
    "        for a in range(len(items)):\n",
    "            if items[a].value:\n",
    "                try:\n",
    "                    data_dump[row] = np.median(channel_array[str(items[a].description)])\n",
    "                except TypeError:\n",
    "                    data_dump[row] = 0\n",
    "                    print(\n",
    "                        \"error in column\",\n",
    "                        items[a].description,\n",
    "                        \"-- might be text, not a number\",\n",
    "                    )\n",
    "                row += 1\n",
    "\n",
    "    return data_dump\n",
    "\n",
    "\n",
    "# ----------------------------------MAIN--------------------------------------\n",
    "\n",
    "numItems = sum([items[a].value for a in range(len(items))]) + int(filter_locs) + 1\n",
    "data_total = np.zeros((numItems * len(channels), len(points_list)))\n",
    "col = 0\n",
    "for i in natsorted(points_list):\n",
    "    # Open File\n",
    "    print(i)\n",
    "    points = pd.read_csv(os.path.join(folder, i))\n",
    "\n",
    "    # Identify column titles\n",
    "    channelTitle = [\n",
    "        p\n",
    "        for p in points.columns\n",
    "        if (\"channel\" in p or \"Channel\" in p) and (\"Name\" not in p)\n",
    "    ][0]\n",
    "    filter_channels = [str(c)[0] for c in channels]\n",
    "    frameTitle = [p for p in points.columns if (\"frame\" in p or \"Frame\" in p)][0]\n",
    "    if \"localization precision (nm)\" in points.columns:\n",
    "        if \"CRLBXPosition\" not in points.columns:\n",
    "            points[\"CRLBXPosition\"] = (\n",
    "                points[\"localization precision (nm)\"]\n",
    "                * points[\"localization precision (nm)\"]\n",
    "            )\n",
    "    elif \"CRLBXPosition\" in points.columns:\n",
    "        points[\"localization precision (nm)\"] = np.sqrt(\n",
    "            points[\"CRLBXPosition\"] + points[\"CRLBYPosition\"]\n",
    "        )\n",
    "    else:\n",
    "        points[\"localization precision (nm)\"] = (\n",
    "            points[\"X precision (nm)\"] + points[\"Y precision (nm)\"]\n",
    "        ) / 2\n",
    "\n",
    "    # Set up row columns for output file\n",
    "    numChannels = len(channels)\n",
    "    numItems = sum([items[a].value for a in range(len(items))]) + int(filter_locs) + 1\n",
    "    # Set up row names\n",
    "    row_titles = []\n",
    "    for c in range(numChannels):\n",
    "        row_titles.append(\"Channel {} Points\".format(str(channels[c])[0]))\n",
    "        if filter_locs:\n",
    "            row_titles.append(\n",
    "                \"Channel {} Points Post-Filtering\".format(str(channels[c])[0])\n",
    "            )\n",
    "        for e in range(len(items)):\n",
    "            if items[e].value == 1:\n",
    "                row_titles.append(\n",
    "                    \"Channel {} {}\".format(str(channels[c])[0], items[e].description)\n",
    "                )\n",
    "\n",
    "    if drift_correction:\n",
    "        # Identify more column titles and perform drift correction\n",
    "        xTitle = [\n",
    "            p for p in points.columns if (p == \"x (nm)\" or p == \"X (nm)\" or p == \"x\")\n",
    "        ][0]\n",
    "        yTitle = [\n",
    "            p for p in points.columns if (p == \"y (nm)\" or p == \"Y (nm)\" or p == \"y\")\n",
    "        ][0]\n",
    "        drift_file = [k for k in drift_files if (i[:-4] in k)][0]\n",
    "        drift = pd.read_csv(os.path.join(folder, drift_file))\n",
    "        for di in track(points.index, description=\"Drift Correction Progress\"):\n",
    "            curr_frame = points[frameTitle][di]\n",
    "            try:\n",
    "                curr_x_drift = drift.iloc[int(curr_frame)][\"x-drift (nm)\"]\n",
    "                curr_y_drift = drift.iloc[int(curr_frame)][\"y-drift (nm)\"]\n",
    "\n",
    "                points.loc[di, xTitle] -= curr_x_drift\n",
    "                points.loc[di, yTitle] -= curr_y_drift\n",
    "            except IndexError:\n",
    "                pass\n",
    "        if save_ints == True:\n",
    "            points.to_csv(os.path.join(folder, \"{}_driftcorrected.csv\".format(i)))\n",
    "    if filter_locs:\n",
    "        # Filter then analyze\n",
    "        points_filtered = filter(points, filters_file, channels, channelTitle)\n",
    "        data_column = analyze(\n",
    "            points_filtered,\n",
    "            items,\n",
    "            channels,\n",
    "            filter_locs,\n",
    "            points,\n",
    "            channelTitle,\n",
    "            frameTitle,\n",
    "            row_titles,\n",
    "        )\n",
    "    else:\n",
    "        # Analyze\n",
    "        data_column = analyze(\n",
    "            points,\n",
    "            items,\n",
    "            channels,\n",
    "            filter_locs,\n",
    "            \"\",\n",
    "            channelTitle,\n",
    "            frameTitle,\n",
    "            row_titles,\n",
    "        )\n",
    "    data_total[:, col] = data_column\n",
    "    col += 1\n",
    "\n",
    "df = pd.DataFrame(data_total, columns=natsorted(points_list))\n",
    "df.index = row_titles\n",
    "df_name = \"{}_{}_drifted{}_filter{}_output.csv\".format(\n",
    "    os.path.split(folder)[-1], keyword, drift_correction, filter_locs\n",
    ")\n",
    "df.to_csv(os.path.join(folder, df_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c650f2c5-ab9e-4c3a-894f-a142bf58f929",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smlm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
