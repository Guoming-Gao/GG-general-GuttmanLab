import os
import pandas as pd
import json
import glob

def generate_consolidated_report(results_dir=None, omit_snps=None):
    if results_dir is None:
        results_dir = os.path.join(".", "results")

    ref_dir = os.path.join(results_dir, "ref_seq")
    quant_dir = os.path.join(results_dir, "quantification")
    stoich_dir = os.path.join(results_dir, "stoichiometry")
    reports_dir = os.path.join(results_dir, "reports")

    os.makedirs(reports_dir, exist_ok=True)
    report_path = os.path.join(reports_dir, "Automated_Summary_Report.md")

    # 1. Load Reference Info
    snp_file = os.path.join(ref_dir, "snps.json")
    snps = []
    if os.path.exists(snp_file):
        with open(snp_file, "r") as f:
            snps = json.load(f)

    quant_files = glob.glob(os.path.join(quant_dir, "*_quant.csv"))
    quant_data = []
    for f in quant_files:
        df = pd.read_csv(f)
        sample = os.path.basename(f).replace("_quant.csv", "")
        # Consistent with quantify_alleles.py and compare_datasets.py
        b6 = len(df[df['Allele'].str.startswith('B6', na=False)])
        cast = len(df[df['Allele'].str.startswith('Cast', na=False)])
        denom = b6+cast
        ratio = cast / denom if denom > 0 else 0
        quant_data.append({
            "Sample": sample,
            "Total Reads": len(df),
            "B6": b6,
            "Cast": cast,
            "Cast Ratio": f"{ratio:.3f}"
        })
    quant_df = pd.DataFrame(quant_data)

    # 3. Gather Stoichiometry Results
    stoich_file = os.path.join(stoich_dir, "stoichiometry_summary.csv")
    stoich_df = pd.DataFrame()
    if os.path.exists(stoich_file):
        stoich_df = pd.read_csv(stoich_file)

    # Build Markdown
    lines = [
        "# Xist SNP Analysis: Automated Summary Report",
        "",
        "This report was automatically generated from the analysis results.",
        "",
        "## 1. Reference Architecture",
        f"Amplicon mapped to genomic region defined in `target_amplicon.fa`.",
        "",
        "| SNP Index | Local Pos | B6 | Cast |",
        "| :--- | :--- | :--- | :--- |"
    ]

    omit = []
    if omit_snps:
        omit = [int(i.strip()) for i in omit_snps.split(",")]

    for i, s in enumerate(snps):
        idx = i + 1
        if idx in omit:
            lines.append(f"| ~~SNP {idx}~~ | ~~{s['local_pos']}~~ | ~~{s['b6']}~~ | ~~{s['cast']}~~ | (Omitted)")
        else:
            lines.append(f"| SNP {idx} | {s['local_pos']} | **{s['b6']}** | **{s['cast']}** |")

    lines.extend([
        "",
        "## 2. Allele Quantification Summary",
        "",
        quant_df.to_markdown(index=False),
        "",
        "## 3. Stoichiometry & Co-occurrence",
        "Higher values in 'ALL_SNPS' indicate higher confidence in amplicon-specific allele assignment.",
        "",
        stoich_df.to_markdown(index=False) if not stoich_df.empty else "No stoichiometry data found.",
        "",
        "## 4. Analysis Parameters",
        "- **Results Directory**: " + results_dir,
        f"- **Reference**: `{os.path.join(results_dir, 'ref_seq', 'target_amplicon.fa')}`",
        "- **Toolchain**: minimap2, samtools, pysam",
        "",
        "---",
        "*Report generated by Antigravity Pipeline.*"
    ])

    with open(report_path, "w") as f:
        f.write("\n".join(lines))

    print(f"Report generated: {report_path}")

if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser(description="Generate consolidated report.")
    parser.add_argument("--results_dir", default=None, help="Results directory (default: ./results)")
    parser.add_argument("--omit_snps", type=str, default=None, help="Comma-separated SNP indices to omit (1-based)")
    args = parser.parse_args()
    generate_consolidated_report(results_dir=args.results_dir, omit_snps=args.omit_snps)
